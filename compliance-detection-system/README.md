# CDS - Compliance Detection System 

> **MVP for detecting geo-specific compliance requirements in code features using static analysis + runtime probes + LLM reasoning**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Git
- (Optional) Google Cloud Project with Vertex AI enabled

### 1-Command Demo

```bash
# Clone and setup
git clone <your-repo-url> && cd compliance-detection-system

# Install dependencies (using pip)
pip install -e .

# Set up environment
cp .env.example .env
# Edit .env with your Google Cloud project details (optional for demo)

# Run the complete pipeline
cds pipeline --dataset ./data/sample_dataset.csv --output ./artifacts/final.csv --report ./artifacts/report.html
```

**Demo Output:**
- ğŸ“Š `./artifacts/final.csv` - Compliance analysis results
- ğŸ“‹ `./artifacts/report.html` - Interactive HTML report
- ğŸ—‚ï¸ `./artifacts/evidence/` - Detailed evidence files

### Testing with Dataset Variations

The system includes three specialized dataset variations with intentional compliance and security issues for testing:

#### ğŸ“‹ Run with Original Comprehensive Dataset
```bash
# Test general compliance detection (COPPA, GDPR, Utah Act)
python demo_pipeline.py original_comprehensive_focused

# Features: User registration, content recommendation, crisis intervention
# Focus: General compliance with intentional gaps
```

#### ğŸ”’ Run with Enterprise Security Dataset
```bash
# Test enterprise security vulnerability detection
python demo_pipeline.py enterprise_security_focused

# Features: Threat detection, zero trust, IAM, security monitoring
# Focus: Security vulnerabilities and enterprise compliance gaps
```

#### ğŸŒ Run with Global Expansion Dataset
```bash
# Test international compliance and data sovereignty
python demo_pipeline.py global_expansion_focused

# Features: Multi-region compliance, localization, cross-border transfers
# Focus: International regulations (GDPR, CCPA, PIPEDA, LGPD)
```

#### ğŸ¯ What These Datasets Test
Each dataset contains **intentional issues** for validation:

**PRD-Level Issues:**
- Missing age verification or COPPA compliance gaps
- Inadequate data retention/deletion policies  
- Missing consent management details
- Insufficient privacy disclosures

**TRD-Level Issues:**
- Missing input validation (SQL injection risks)
- Weak authentication/authorization mechanisms
- Insecure data handling practices
- Inadequate error handling exposing sensitive data

**Code-Level Issues:**
- Hardcoded secrets, API keys, passwords
- SQL injection vulnerabilities
- Missing authentication on sensitive endpoints
- Weak encryption or plaintext PII storage

#### ğŸ“Š Expected Results
- **Original Comprehensive**: 3 features processed, multiple compliance gaps detected
- **Enterprise Security**: 4 features processed, security vulnerabilities flagged
- **Global Expansion**: 4 features processed, international compliance issues found

All results include:
- ğŸ“ˆ **CSV Results**: `artifacts/comprehensive_demo_results.csv`
- ğŸŒ **HTML Report**: `artifacts/comprehensive_demo_report.html` 
- ğŸ“ **Evidence Files**: `artifacts/evidence/` directory
- ğŸš© **Issue Detection**: Known vulnerabilities flagged with `needs_review=True`

#### ğŸ” Generating Evidence Files (Required)

Before running the pipeline, generate evidence files from the dataset artifacts:

```bash
# Generate evidence files for all dataset variations
python generate_evidence.py

# This creates evidence JSON files in artifacts/evidence/
# Required for the pipeline to analyze the intentional issues
```

The evidence generator:
- âœ… Creates evidence files for all 11 features across 3 dataset variations
- âœ… Extracts content from PRDs, TRDs, and implementation code  
- âœ… Pre-analyzes artifacts for compliance and security issues
- âœ… Enables the pipeline to detect intentional vulnerabilities

#### ğŸ“ Dataset Variations Structure
```
dataset_variations/
â”œâ”€â”€ original_comprehensive_focused/    # General compliance (3 features)
â”œâ”€â”€ enterprise_security_focused/       # Security-focused (4 features)  
â””â”€â”€ global_expansion_focused/          # International (4 features)
```

Each variation contains:
- ğŸ“Š **Feature datasets** (CSV files with metadata)
- ğŸ“„ **Comprehensive artifacts** (PRDs, TRDs, design docs)
- ğŸ’» **Implementation code** (with intentional vulnerabilities)
- ğŸ¯ **Intentional issues** for testing compliance detection

### âš¡ Quick Reference

```bash
# 1. Generate evidence files (run once)
python generate_evidence.py
# Creates evidence files for all 11 features across 3 dataset variations

# 2. Test with different datasets
python demo_pipeline.py original_comprehensive_focused    # General compliance
python demo_pipeline.py enterprise_security_focused       # Security vulnerabilities  
python demo_pipeline.py global_expansion_focused          # International compliance

# 3. View results
start artifacts/comprehensive_demo_report.html             # HTML report (Windows)
open artifacts/comprehensive_demo_report.html              # HTML report (Mac/Linux)  
code artifacts/comprehensive_demo_results.csv              # CSV results
```

**Expected Output per Run:**
- ğŸ“Š 3-4 features processed (varies by dataset)
- ğŸš© Multiple intentional issues detected  
- ğŸ“‹ Detailed evidence files generated
- ğŸ¯ All features flagged for manual review (`needs_review=True`)
- âš¡ Uses existing compliance rules from `./data/rules/compliance_rules.json`

## ğŸ—ï¸ Architecture

```
â”Œâ”€ Static Scanner â”€â”    â”Œâ”€ Runtime Probes â”€â”    â”Œâ”€ Rules Engine â”€â”
â”‚  â€¢ Semgrep       â”‚    â”‚  â€¢ Playwright     â”‚    â”‚  â€¢ JSON Logic  â”‚
â”‚  â€¢ Tree-sitter   â”‚ -> â”‚  â€¢ Personas       â”‚ -> â”‚  â€¢ Confidence  â”‚
â”‚  â€¢ AST Analysis  â”‚    â”‚  â€¢ UI States      â”‚    â”‚  â€¢ Regulations â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                        â”‚                        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Evidence Pack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Static + Runtime + Metadata + Files     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    â”Œâ”€â”€â”€ LLM Analysis (Gemini 1.5) â”€â”€â”€â”
                    â”‚  â€¢ Compliance Reasoning          â”‚
                    â”‚  â€¢ Regulatory Mapping           â”‚ 
                    â”‚  â€¢ Confidence Scoring           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                         â”Œâ”€ Final Record â”€â”
                         â”‚  CSV + HTML    â”‚
                         â”‚   Reports      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Core Commands

### Static Analysis
```bash
# Scan repository for compliance patterns
cds scan --repo ./sample_repo --feature user_registration

# Output: ./artifacts/evidence/user_registration.json
```

### Runtime Probing
```bash
# Test with different personas
cds probe --persona ut_minor --url http://localhost:3000 --feature live_test

# Available personas: ut_minor, fr_adult, ca_teen, uk_adult
```

### Rules Evaluation
```bash
# Apply compliance rules to evidence
cds evaluate --feature user_registration

# Uses: JSON Logic rules from ./data/rules/compliance_rules.json
```

### LLM Explanation
```bash
# Generate AI-powered compliance analysis
cds explain --feature user_registration

# Output: Detailed reasoning + regulatory mapping
```

### Batch Processing
```bash
# Process entire dataset
cds pipeline --dataset ./data/sample_dataset.csv
```

## ğŸ“Š What Gets Detected

### Static Analysis Signals
- **ğŸŒ Geographic Branching**: Country lists, region checks
- **ğŸ‘¶ Age Verification**: Age gate imports, minor checks  
- **ğŸ  Data Residency**: Region configurations, storage locations
- **ğŸ“‹ Reporting Clients**: NCMEC, CSAM detection systems
- **ğŸš© Feature Flags**: Compliance-related toggles
- **ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Parental Controls**: Consent systems, restrictions

### Runtime Probe Signals  
- **ğŸ­ Persona Testing**: ut_minor (UT, 16), fr_adult (FR, 25)
- **ğŸš« Blocked Actions**: Age-restricted features, geo-blocks
- **ğŸ–¥ï¸ UI States**: Cookie banners, consent modals, privacy settings
- **ğŸ Feature Flags**: Runtime flag resolutions
- **ğŸŒ Network Traces**: API calls, data residency patterns

### Compliance Rules Detected
- **Utah Social Media Act**: Minor curfew enforcement (10:30 PM - 6:30 AM)
- **NCMEC Reporting**: Mandatory CSAM reporting requirements
- **EU DSA**: Transparency reports, user flagging, appeals
- **GDPR**: Lawful basis, data subject rights, privacy by design
- **COPPA**: Parental consent for children under 13
- **State Privacy Laws**: Default-off privacy features for minors

## ğŸ”§ Configuration

### Environment Variables
```bash
# Required for LLM analysis (optional for demo)
GOOGLE_CLOUD_PROJECT=your-project-id
GEMINI_LOCATION=us-central1

# Optional configurations
DATA_DIR=./data
ARTIFACT_DIR=./artifacts
LOG_LEVEL=INFO
```

### Custom Rules
Add rules to `./data/rules/compliance_rules.json`:

```json
{
  "id": "CUSTOM_RULE",
  "name": "My Custom Compliance Rule",
  "logic": {
    "and": [
      {"==": [{"var": "static.pf_controls"}, true]},
      {"<": [{"var": "runtime.persona.age"}, 18]}
    ]
  },
  "requires_controls": ["age_verification"],
  "regulations": ["My Regulation"],
  "severity": "medium"
}
```

### Custom Semgrep Rules
Extend `./data/rules/semgrep.yml`:

```yaml
- id: my-compliance-pattern
  pattern: my_compliance_function(...)
  message: "Custom compliance pattern detected"
  languages: [python, javascript]
  severity: INFO
```

## ğŸ“ Project Structure

```
compliance-detection-system/
â”œâ”€â”€ cds/                    # Main package
â”‚   â”œâ”€â”€ cli/               # CLI interface (Typer)
â”‚   â”œâ”€â”€ scanner/           # Static analysis (Semgrep + Tree-sitter)
â”‚   â”œâ”€â”€ runtime/           # Playwright probing
â”‚   â”œâ”€â”€ rules/             # JSON Logic rules engine  
â”‚   â”œâ”€â”€ llm/               # Gemini 1.5 integration
â”‚   â””â”€â”€ evidence/          # Data models + pipeline
â”œâ”€â”€ data/                  # Configuration & rules
â”‚   â”œâ”€â”€ rules/            # Semgrep + JSON Logic rules
â”‚   â”œâ”€â”€ policy_snippets.json  # Regulatory text snippets
â”‚   â””â”€â”€ sample_dataset.csv    # Demo dataset
â”œâ”€â”€ sample_repo/           # Demo repository with compliance patterns
â”œâ”€â”€ artifacts/             # Output directory
â”‚   â”œâ”€â”€ evidence/         # Evidence JSON files
â”‚   â”œâ”€â”€ final.csv         # Results export
â”‚   â””â”€â”€ report.html       # HTML report
â””â”€â”€ scripts/              # Utility scripts
```

## ğŸ§ª Development

### Setup Development Environment
```bash
# Install in development mode
pip install -e ".[dev]"

# Run tests
pytest

# Type checking
mypy cds/

# Code formatting
ruff format cds/
ruff check cds/
```

### Adding New Scanners
```python
# cds/scanner/my_scanner.py
class MyScanner:
    def scan(self, repo_path: Path) -> Dict[str, List[Dict]]:
        # Your custom scanning logic
        return {"my_signal_type": [{"file": "test.py", "line": 1}]}
```

### Adding New Rules
```python
# Add to compliance_rules.json
{
  "id": "MY_RULE",
  "logic": {"==": [{"var": "static.my_signal"}, true]},
  "requires_controls": ["my_control"],
  "regulations": ["My Regulation"]
}
```

## ğŸ“Š Sample Output

### CSV Export Format
```csv
feature_id,requires_geo_logic,reasoning,confidence,severity
user_registration,true,"Geographic branching detected with countries US;CA;EU and age verification systems",0.85,high
content_recommendation,true,"NCMEC reporting client detected with recommendation system flags",0.92,critical
```

### HTML Report
Interactive report with:
- ğŸ“ˆ Summary statistics dashboard
- ğŸ” Feature-by-feature analysis  
- ğŸ“‹ Regulatory requirements mapping
- ğŸ”— Code reference links
- âš ï¸ Review recommendations

## ğŸš€ Deployment

### Docker
```bash
# Build image
docker build -t cds .

# Run pipeline
docker run -v $(pwd)/data:/data -v $(pwd)/artifacts:/artifacts cds \
  pipeline --dataset /data/sample_dataset.csv
```

### CI/CD (GitHub Actions)
```yaml
- name: Run Compliance Detection
  run: |
    pip install -e .
    cds pipeline --dataset ./data/production_dataset.csv
    
- name: Upload Results
  uses: actions/upload-artifact@v3
  with:
    name: compliance-results
    path: artifacts/
```

## ğŸ¯ Success Metrics

### MVP Completion âœ…
- [x] All CLI commands functional
- [x] End-to-end pipeline produces valid CSV
- [x] HTML reports render with evidence links  
- [x] Demo completes in under 3 minutes

### Quality Indicators âš¡
- [x] Static analysis detects 6+ compliance patterns
- [x] Rules engine evaluates 7+ regulatory requirements
- [x] LLM integration provides detailed reasoning
- [x] Pipeline processes 10+ features reliably

### Scalability Ready ğŸ“ˆ
- [x] SQLite-based registry (Postgres-ready)
- [x] Modular scanner architecture
- [x] Cloud-ready LLM integration
- [x] Extensible rules framework

## ğŸ“œ Supported Regulations

| Regulation | Jurisdiction | Coverage | Severity |
|------------|-------------|----------|----------|
| **Utah Social Media Act** | Utah, USA | Minor curfew restrictions | High |
| **NCMEC Reporting** | United States | CSAM mandatory reporting | Critical |
| **EU Digital Services Act** | European Union | Transparency & appeals | High |  
| **GDPR** | EU/EEA/UK | Data subject rights | High |
| **COPPA** | United States | Children under 13 | Critical |
| **CCPA** | California, USA | Consumer privacy rights | Medium |
| **UK Age Appropriate Design** | United Kingdom | Child safety by design | High |
| **Texas HB 18** | Texas, USA | Minor privacy defaults | Medium |

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/amazing-scanner`
3. **Add your code**: Follow existing patterns in `cds/`
4. **Write tests**: Add to `tests/` directory
5. **Submit PR**: Include demo output and documentation

### Contribution Areas
- ğŸ” **New Scanners**: AST patterns, regex rules, API integrations
- âš–ï¸ **Compliance Rules**: New jurisdictions, regulatory updates
- ğŸ­ **Runtime Probes**: Additional personas, test scenarios
- ğŸ¤– **LLM Improvements**: Prompt engineering, fallback logic
- ğŸ“Š **Reporting**: New export formats, visualizations

## ğŸ“ Support

- ğŸ“– **Documentation**: See `docs/` directory
- ğŸ› **Issues**: GitHub Issues for bugs and features  
- ğŸ’¬ **Discussions**: GitHub Discussions for questions
- ğŸ“§ **Contact**: team@cds.dev

## ğŸ“„ License

MIT License - see `LICENSE` file for details.

## ğŸ™ Acknowledgments

- **Semgrep**: Static analysis rules engine
- **Playwright**: Runtime browser automation
- **Google Vertex AI**: LLM analysis capabilities  
- **JSON Logic**: Flexible rules evaluation
- **TikTok Hackathon**: Inspiration and opportunity

---

**Built with â¤ï¸ for compliance automation**

*CDS v0.1.0 - Detect compliance requirements before they become problems*
